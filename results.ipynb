{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14feeb90-d8c3-4422-b61b-1a9d2008c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61d6b8c-a523-4b25-95ff-d5fe0e0e2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574274e9-4683-4061-9ed3-b7047aaa512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Sampler,\n",
    "    TensorDataset,\n",
    "    WeightedRandomSampler,\n",
    "    random_split,\n",
    ")\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    GPT2Config,\n",
    "    GPT2ForSequenceClassification,\n",
    "    GPT2Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac3a2e1-4614-4628-83be-65129bc4f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2c273a4-4048-4308-b96a-ea493c7cdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fe4b1c06-bb71-4020-902e-e33bbe476e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matthews(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return matthews_corrcoef(pred_flat, labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd8e01-7871-463f-9e69-bcce5c143f91",
   "metadata": {},
   "source": [
    "Get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6002f907-aff8-4d47-920f-7bd0eb3c04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipurl = \"https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\"\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e4df7b2e-869c-4876-a5ba-9c8f312142fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain_dev.tsv  in_domain_train.tsv\tout_of_domain_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls data/cola_public/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49a8d754-93c5-411e-9fbd-82a9fe65f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    do_lower_case=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd4123e-78cc-4f9b-baf4-3397215c21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gtp2 = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    do_lower_case=True,\n",
    ")\n",
    "tokenizer_gtp2.pad_token = tokenizer_gtp2.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "96a56129-b3f8-456c-b4d7-a01de8dfd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, tokenizer, bs=60, split=True):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    texts = df.iloc[:, 2].to_list()\n",
    "    labels = torch.from_numpy(df.iloc[:, 0].to_numpy())\n",
    "\n",
    "    def get_ids(texts):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for sent in texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                sent,  # Sentence to encode.\n",
    "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                max_length=64,  # Pad & truncate all sentences.\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,  # Construct attn. masks.\n",
    "                return_tensors=\"pt\",  # Return pytorch tensors.\n",
    "            )\n",
    "            input_ids.append(encoded_dict[\"input_ids\"])\n",
    "            attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        return input_ids, attention_masks\n",
    "\n",
    "    input_ids, attention_masks = get_ids(texts)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    counts = np.bincount(labels.numpy())\n",
    "    labels_weights = 1.0 / counts\n",
    "    weights = labels_weights[labels.numpy()]\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    if split:\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "        dataloader_train = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "        dataloader_val = DataLoader(val_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "        return dataloader_train, dataloader_val\n",
    "    else:\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8f3a4bc5-8146-46bd-9955-04f6874d8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_48591/4208486169.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_train_bert, dataloader_val_bert = preprocess(df, tokenizer_bert)\n",
    "dataloader_train_gpt2, dataloader_val_gpt2 = preprocess(df, tokenizer_gtp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "867bf261-ba64-4f7e-b525-5c9e47f832c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b_82</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This book I enjoyed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ks08</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Up what did he look?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc01</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John saw the man in the room.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l-93</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Tony broke herself on the ann.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Ron asked that the potion was ready</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>I expect to double more than my profits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l-93</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The bag is bulging.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bc01</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Runs Mary the marathon?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sks13</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Whether she will win is a question Mary never ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Jennie smiled the sandwich.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Grammaticality Empty                                           Sentence\n",
       "b_82                1   NaN                               This book I enjoyed.\n",
       "ks08                1   NaN                               Up what did he look?\n",
       "bc01                1   NaN                      John saw the man in the room.\n",
       "l-93                0     *                     Tony broke herself on the ann.\n",
       "ad03                0     *                Ron asked that the potion was ready\n",
       "c_13                0     *           I expect to double more than my profits.\n",
       "l-93                1   NaN                                The bag is bulging.\n",
       "bc01                0     *                            Runs Mary the marathon?\n",
       "sks13               1   NaN  Whether she will win is a question Mary never ...\n",
       "c_13                0     *                        Jennie smiled the sandwich."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9afafa3e-a288-44ef-85de-b1e576fd58a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_48591/4208486169.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_id_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_id_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3589055d-656c-4cf3-b9e4-16528cb23a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48591/4208486169.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/out_of_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_od_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_od_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "57d90d28-7df6-43df-bc0a-95752702738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(model, dataloader_t, dataloader_w, seed_val=42, epochs=3):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    losses_tr = []\n",
    "    losses_ev = []\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_t):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_train_loss += loss.item()\n",
    "            # losses_tr.append(loss.item())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(dataloader_t)\n",
    "        losses_tr.append(avg_train_loss)\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        total_eval_MCC = 0\n",
    "\n",
    "        for batch in dataloader_w:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(\n",
    "                    b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels,\n",
    "                )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(dataloader_w)\n",
    "        # avg_val_MCC = total_eval_MCC / len(dataloader_w)\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_w)\n",
    "        print(f\"Eval accuracy: {round(avg_val_accuracy, 4)}, eval loss: {round(avg_val_loss, 4)}\")\n",
    "        losses_ev.append(avg_val_loss)\n",
    "    return losses_tr, losses_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "48a5c217-5983-4e9a-afeb-af4edea857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "def test_model(model, dataloader):\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_eval_MCC = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "    avg_accuracy = total_eval_accuracy / len(dataloader)\n",
    "    avg_MCC = total_eval_MCC / len(dataloader)\n",
    "    avg_loss = total_eval_loss / len(dataloader)\n",
    "    print(f\"Test accuracy: {round(avg_accuracy, 4)}, test loss: {round(avg_loss, 4)}, test MCC: {round(avg_MCC, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a5f41-b535-4ff1-b800-fc1b0a8428f7",
   "metadata": {},
   "source": [
    "### 1. Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "456c86e9-ed51-48d3-9d00-71a4f77d7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "\n",
    "model_bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ad99037f-42a1-4e8d-b2e9-084027477fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_bert.parameters(),\n",
    "    lr=2e-5,\n",
    "    eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e6c3a340-680c-4d36-a9ff-d1bcceb255c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "total_steps = len(dataloader_train_bert) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b95bf91b-cfaa-4645-850b-77e8e6e75644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.82\n",
      "  MCC: 0.53\n",
      "  Accuracy: 0.82\n",
      "  MCC: 0.54\n",
      "  Accuracy: 0.82\n",
      "  MCC: 0.54\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(model_bert, dataloader_train_bert, dataloader_val_bert, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b2909cb-3202-44f6-bcde-ead0b1bc63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label='Train')\n",
    "plt.plot(losses_ev, label='Eval')\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3136db78-b141-419b-a1a4-61722572f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8246, test loss: 0.4631, test MCC: 0.5726\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_id_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b9996072-f64f-46e7-a1d7-b0117a5e4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8171, test loss: 0.5366, test MCC: 0.5499\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_od_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "439bcf6f-c07b-4a0c-a251-9a6c40105e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb1c91-5cb4-4804-b730-1468abca051b",
   "metadata": {},
   "source": [
    "### 2. GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e110b794-6623-487d-ad45-4a8ad0d2f52d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpt2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "model_gpt2.config.pad_token_id = model_gpt2.config.eos_token_id\n",
    "model_gpt2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e1448595-4d97-49d0-92cb-0e35802138a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_gpt2.parameters(),\n",
    "    lr=5e-5,\n",
    "    eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "50ef180e-f2aa-4cf1-9594-bfb1bc6a4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "total_steps = len(dataloader_train_gpt2) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07316047-acea-4da8-a850-cbfe72c5c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.67\n",
      "  MCC: -0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.69\n",
      "  MCC: 0.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.72\n",
      "  MCC: 0.25\n",
      "  Accuracy: 0.75\n",
      "  MCC: 0.41\n",
      "  Accuracy: 0.76\n",
      "  MCC: 0.41\n",
      "  Accuracy: 0.75\n",
      "  MCC: 0.40\n",
      "  Accuracy: 0.75\n",
      "  MCC: 0.39\n",
      "  Accuracy: 0.77\n",
      "  MCC: 0.43\n",
      "  Accuracy: 0.77\n",
      "  MCC: 0.43\n",
      "  Accuracy: 0.78\n",
      "  MCC: 0.44\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_gpt2, dataloader_train_gpt2, dataloader_val_gpt2, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7edd1ef4-905b-4e89-a8fe-667156b9faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label='Train')\n",
    "plt.plot(losses_ev, label='Eval')\n",
    "plt.legend()\n",
    "plt.ylim(0, 2)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "902cb88a-c6bd-4ae9-9e1f-13a330c18433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8208, test loss: 0.8069, test MCC: 0.5321\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_id_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "66e55e9b-b403-4f29-bf82-00e63388211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7412, test loss: 1.1424, test MCC: 0.3616\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_od_gpt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
