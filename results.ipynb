{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14feeb90-d8c3-4422-b61b-1a9d2008c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61d6b8c-a523-4b25-95ff-d5fe0e0e2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574274e9-4683-4061-9ed3-b7047aaa512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Sampler,\n",
    "    TensorDataset,\n",
    "    WeightedRandomSampler,\n",
    "    random_split,\n",
    ")\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    GPT2Config,\n",
    "    GPT2ForSequenceClassification,\n",
    "    GPT2Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac3a2e1-4614-4628-83be-65129bc4f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2c273a4-4048-4308-b96a-ea493c7cdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4b1c06-bb71-4020-902e-e33bbe476e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matthews(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return matthews_corrcoef(pred_flat, labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd8e01-7871-463f-9e69-bcce5c143f91",
   "metadata": {},
   "source": [
    "Get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6002f907-aff8-4d47-920f-7bd0eb3c04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipurl = \"https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\"\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4df7b2e-869c-4876-a5ba-9c8f312142fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain_dev.tsv  in_domain_train.tsv\tout_of_domain_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls data/cola_public/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a8d754-93c5-411e-9fbd-82a9fe65f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    do_lower_case=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd4123e-78cc-4f9b-baf4-3397215c21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gtp2 = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    do_lower_case=True,\n",
    ")\n",
    "tokenizer_gtp2.pad_token = tokenizer_gtp2.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a56129-b3f8-456c-b4d7-a01de8dfd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, tokenizer, bs=60, split=True, rand=True):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    texts = df.iloc[:, 2].to_list()\n",
    "    labels = torch.from_numpy(df.iloc[:, 0].to_numpy())\n",
    "\n",
    "    def get_ids(texts):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for sent in texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                sent,  # Sentence to encode.\n",
    "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                max_length=64,  # Pad & truncate all sentences.\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,  # Construct attn. masks.\n",
    "                return_tensors=\"pt\",  # Return pytorch tensors.\n",
    "            )\n",
    "            input_ids.append(encoded_dict[\"input_ids\"])\n",
    "            attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        return input_ids, attention_masks\n",
    "\n",
    "    input_ids, attention_masks = get_ids(texts)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    if split:\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "        dataloader_train = DataLoader(train_dataset, batch_size=bs, shuffle=rand)\n",
    "        dataloader_val = DataLoader(val_dataset, batch_size=bs, shuffle=rand)\n",
    "\n",
    "        return dataloader_train, dataloader_val\n",
    "    else:\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3a4bc5-8146-46bd-9955-04f6874d8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_train_bert, dataloader_val_bert = preprocess(df, tokenizer_bert)\n",
    "dataloader_train_gpt2, dataloader_val_gpt2 = preprocess(df, tokenizer_gtp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "867bf261-ba64-4f7e-b525-5c9e47f832c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l-93</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This machine records well.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l-93</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amanda carried the package to New York.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_73</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Mary's happy about her work, and John's about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I blew the building up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cj99</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When you eat more, you want correspondingly less.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l-93</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They praised them as volunteers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rhl07</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake kicked the ball halfway to Bill.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b_73</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>She speaks enough clearly to be understood.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ks08</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The monkeys seem eager to leave the meeting.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_13</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We ate at a really fancy restaurant.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Grammaticality Empty                                           Sentence\n",
       "l-93                1   NaN                         This machine records well.\n",
       "l-93                1   NaN            Amanda carried the package to New York.\n",
       "b_73                0     *  Mary's happy about her work, and John's about ...\n",
       "c_13                1   NaN                            I blew the building up.\n",
       "cj99                1   NaN  When you eat more, you want correspondingly less.\n",
       "l-93                1   NaN                   They praised them as volunteers.\n",
       "rhl07               1   NaN              Jake kicked the ball halfway to Bill.\n",
       "b_73                0     *        She speaks enough clearly to be understood.\n",
       "ks08                1   NaN       The monkeys seem eager to leave the meeting.\n",
       "c_13                1   NaN               We ate at a really fancy restaurant."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9afafa3e-a288-44ef-85de-b1e576fd58a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_id_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_id_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3589055d-656c-4cf3-b9e4-16528cb23a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/out_of_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_od_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_od_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57d90d28-7df6-43df-bc0a-95752702738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(model, dataloader_t, dataloader_w, seed_val=42, epochs=3):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    losses_tr = []\n",
    "    losses_ev = []\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_t):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_train_loss += loss.item()\n",
    "            # losses_tr.append(loss.item())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(dataloader_t)\n",
    "        losses_tr.append(avg_train_loss)\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        total_eval_MCC = 0\n",
    "\n",
    "        for batch in dataloader_w:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(\n",
    "                    b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels,\n",
    "                )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            # total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(dataloader_w)\n",
    "        # avg_val_MCC = total_eval_MCC / len(dataloader_w)\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_w)\n",
    "        print(\n",
    "            f\"Eval accuracy: {round(avg_val_accuracy, 4)}, eval loss: {round(avg_val_loss, 4)}\"\n",
    "        )\n",
    "        losses_ev.append(avg_val_loss)\n",
    "    return losses_tr, losses_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48a5c217-5983-4e9a-afeb-af4edea857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "def test_model(model, dataloader):\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_eval_MCC = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "    avg_accuracy = total_eval_accuracy / len(dataloader)\n",
    "    avg_MCC = total_eval_MCC / len(dataloader)\n",
    "    avg_loss = total_eval_loss / len(dataloader)\n",
    "    print(\n",
    "        f\"Test accuracy: {round(avg_accuracy, 4)}, test loss: {round(avg_loss, 4)}, test MCC: {round(avg_MCC, 4)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a5f41-b535-4ff1-b800-fc1b0a8428f7",
   "metadata": {},
   "source": [
    "### 1. Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456c86e9-ed51-48d3-9d00-71a4f77d7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    classifier_dropout=0.5,    \n",
    ")\n",
    "\n",
    "model_bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad99037f-42a1-4e8d-b2e9-084027477fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_bert.parameters(),\n",
    "    lr=2e-5,\n",
    "    # eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c3a340-680c-4d36-a9ff-d1bcceb255c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "total_steps = len(dataloader_train_bert) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b95bf91b-cfaa-4645-850b-77e8e6e75644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.7975, eval loss: 0.4581\n",
      "Eval accuracy: 0.8036, eval loss: 0.4622\n",
      "Eval accuracy: 0.8164, eval loss: 0.4811\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_bert, dataloader_train_bert, dataloader_val_bert, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b2909cb-3202-44f6-bcde-ead0b1bc63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label=\"Train\")\n",
    "plt.plot(losses_ev, label=\"Eval\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.savefig('res_bert.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3136db78-b141-419b-a1a4-61722572f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.823, test loss: 0.4705, test MCC: 0.5637\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_id_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9996072-f64f-46e7-a1d7-b0117a5e4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8138, test loss: 0.5653, test MCC: 0.5458\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_od_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c58312-bfb4-4edf-a27b-63084eb41c1f",
   "metadata": {},
   "source": [
    "Kaggle res:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eefb242-d675-4599-8168-f1e7a36cfd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"cola_in_domain_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "df_test.insert(1, \"Empty\", 0)\n",
    "df_test['Id'] = 0\n",
    "\n",
    "dataloader_test = preprocess(df_test, tokenizer_bert, split=False, bs=100, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9f1aab-a19a-40c7-9c2c-20dd5e7e2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_l = []\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model_bert(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "        logits = out[1]\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        logits_l += pred_flat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73446cbe-98c6-4973-a64f-dd1326eafbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"cola_in_domain_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "468fafbc-4fd7-417b-874e-388bc7256bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sentence'] = logits_l\n",
    "df_test = df_test.rename(columns={\"Sentence\": \"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1f776eb-8de2-447f-8ed0-c7bc3e455a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "439bcf6f-c07b-4a0c-a251-9a6c40105e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb1c91-5cb4-4804-b730-1468abca051b",
   "metadata": {},
   "source": [
    "### 2. GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e110b794-6623-487d-ad45-4a8ad0d2f52d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpt2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "model_gpt2.config.pad_token_id = model_gpt2.config.eos_token_id\n",
    "model_gpt2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1448595-4d97-49d0-92cb-0e35802138a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_gpt2.parameters(),\n",
    "    lr=10e-5,\n",
    "    # eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50ef180e-f2aa-4cf1-9594-bfb1bc6a4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "total_steps = len(dataloader_train_gpt2) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07316047-acea-4da8-a850-cbfe72c5c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.72, eval loss: 0.5833\n",
      "Eval accuracy: 0.7444, eval loss: 0.5421\n",
      "Eval accuracy: 0.7772, eval loss: 0.497\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_gpt2, dataloader_train_gpt2, dataloader_val_gpt2, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7edd1ef4-905b-4e89-a8fe-667156b9faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label=\"Train\")\n",
    "plt.plot(losses_ev, label=\"Eval\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "902cb88a-c6bd-4ae9-9e1f-13a330c18433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7796, test loss: 0.5333, test MCC: 0.4433\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_id_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66e55e9b-b403-4f29-bf82-00e63388211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7117, test loss: 0.6186, test MCC: 0.3004\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_od_gpt2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
