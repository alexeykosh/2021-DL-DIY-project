{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14feeb90-d8c3-4422-b61b-1a9d2008c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (4.15.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d61d6b8c-a523-4b25-95ff-d5fe0e0e2ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100S-PCIE-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print(\"There are %d GPU(s) available.\" % torch.cuda.device_count())\n",
    "\n",
    "    print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print(\"No GPU available, using the CPU instead.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "574274e9-4683-4061-9ed3-b7047aaa512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import (\n",
    "    DataLoader,\n",
    "    Sampler,\n",
    "    TensorDataset,\n",
    "    WeightedRandomSampler,\n",
    "    random_split,\n",
    ")\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForSequenceClassification,\n",
    "    BertTokenizer,\n",
    "    ElectraForSequenceClassification,\n",
    "    ElectraTokenizer,\n",
    "    GPT2Config,\n",
    "    GPT2ForSequenceClassification,\n",
    "    GPT2Tokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1ac3a2e1-4614-4628-83be-65129bc4f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e2c273a4-4048-4308-b96a-ea493c7cdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fe4b1c06-bb71-4020-902e-e33bbe476e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matthews(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return matthews_corrcoef(pred_flat, labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadd8e01-7871-463f-9e69-bcce5c143f91",
   "metadata": {},
   "source": [
    "Get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6002f907-aff8-4d47-920f-7bd0eb3c04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipurl = \"https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\"\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4df7b2e-869c-4876-a5ba-9c8f312142fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_domain_dev.tsv  in_domain_train.tsv\tout_of_domain_dev.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls data/cola_public/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49a8d754-93c5-411e-9fbd-82a9fe65f029",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_bert = BertTokenizer.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    do_lower_case=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd4123e-78cc-4f9b-baf4-3397215c21cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_gtp2 = GPT2Tokenizer.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    do_lower_case=True,\n",
    ")\n",
    "tokenizer_gtp2.pad_token = tokenizer_gtp2.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0693ce4c-1f09-4d34-a2e1-98cdd61d6912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d888678f77b448f39c5a59ed7dc0aae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d42ce9eeb142a09843a0395166bba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f261c1e667410fa87fb120b2b59e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdf4b408b16413ba7add6b3beb77df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer_electra = ElectraTokenizer.from_pretrained(\n",
    "    \"google/electra-small-discriminator\",\n",
    "    do_lower_case=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a56129-b3f8-456c-b4d7-a01de8dfd1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, tokenizer, bs=60, split=True, rand=True):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    texts = df.iloc[:, 2].to_list()\n",
    "    labels = torch.from_numpy(df.iloc[:, 0].to_numpy())\n",
    "\n",
    "    def get_ids(texts):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for sent in texts:\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                sent,  # Sentence to encode.\n",
    "                add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "                max_length=64,  # Pad & truncate all sentences.\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,  # Construct attn. masks.\n",
    "                return_tensors=\"pt\",  # Return pytorch tensors.\n",
    "            )\n",
    "            input_ids.append(encoded_dict[\"input_ids\"])\n",
    "            attention_masks.append(encoded_dict[\"attention_mask\"])\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "        return input_ids, attention_masks\n",
    "\n",
    "    input_ids, attention_masks = get_ids(texts)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    train_size = int(0.9 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    if split:\n",
    "        train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "        dataloader_train = DataLoader(train_dataset, batch_size=bs, shuffle=rand)\n",
    "        dataloader_val = DataLoader(val_dataset, batch_size=bs, shuffle=rand)\n",
    "\n",
    "        return dataloader_train, dataloader_val\n",
    "    else:\n",
    "        return DataLoader(dataset, batch_size=bs, shuffle=rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f3a4bc5-8146-46bd-9955-04f6874d8c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_train_bert, dataloader_val_bert = preprocess(df, tokenizer_bert)\n",
    "dataloader_train_gpt2, dataloader_val_gpt2 = preprocess(df, tokenizer_gtp2)\n",
    "dataloader_train_electra, dataloader_val_electra = preprocess(df, tokenizer_electra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9afafa3e-a288-44ef-85de-b1e576fd58a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_id_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_id_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)\n",
    "dataloader_test_id_electra = preprocess(df_test, tokenizer_electra, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3589055d-656c-4cf3-b9e4-16528cb23a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"data/cola_public/raw/out_of_domain_dev.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "dataloader_test_od_bert = preprocess(df_test, tokenizer_bert, split=False, bs=100)\n",
    "dataloader_test_od_gpt2 = preprocess(df_test, tokenizer_gtp2, split=False, bs=100)\n",
    "dataloader_test_od_electra = preprocess(df_test, tokenizer_electra, split=False, bs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "57d90d28-7df6-43df-bc0a-95752702738f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train(model, dataloader_t, dataloader_w, seed_val=42, epochs=3):\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "    torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "    losses_tr = []\n",
    "    losses_ev = []\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "        total_train_loss = 0\n",
    "        model.train()\n",
    "        for step, batch in enumerate(dataloader_t):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            model.zero_grad()\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_train_loss += loss.item()\n",
    "            # losses_tr.append(loss.item())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        avg_train_loss = total_train_loss / len(dataloader_t)\n",
    "        losses_tr.append(avg_train_loss)\n",
    "        model.eval()\n",
    "\n",
    "        total_eval_accuracy = 0\n",
    "        total_eval_loss = 0\n",
    "        nb_eval_steps = 0\n",
    "        total_eval_MCC = 0\n",
    "\n",
    "        for batch in dataloader_w:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(\n",
    "                    b_input_ids,\n",
    "                    token_type_ids=None,\n",
    "                    attention_mask=b_input_mask,\n",
    "                    labels=b_labels,\n",
    "                )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            # total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "        avg_val_accuracy = total_eval_accuracy / len(dataloader_w)\n",
    "        # avg_val_MCC = total_eval_MCC / len(dataloader_w)\n",
    "        avg_val_loss = total_eval_loss / len(dataloader_w)\n",
    "        print(\n",
    "            f\"Eval accuracy: {round(avg_val_accuracy, 4)}, eval loss: {round(avg_val_loss, 4)}\"\n",
    "        )\n",
    "        losses_ev.append(avg_val_loss)\n",
    "    return losses_tr, losses_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "48a5c217-5983-4e9a-afeb-af4edea857af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "def test_model(model, dataloader):\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    avg_val_loss = 0\n",
    "    total_eval_MCC = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(\n",
    "                b_input_ids,\n",
    "                token_type_ids=None,\n",
    "                attention_mask=b_input_mask,\n",
    "                labels=b_labels,\n",
    "            )\n",
    "\n",
    "            loss = out[0]\n",
    "            logits = out[1]\n",
    "            total_eval_loss += loss.item()\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to(\"cpu\").numpy()\n",
    "            total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "            total_eval_MCC += matthews(logits, label_ids)\n",
    "\n",
    "    avg_accuracy = total_eval_accuracy / len(dataloader)\n",
    "    avg_MCC = total_eval_MCC / len(dataloader)\n",
    "    avg_loss = total_eval_loss / len(dataloader)\n",
    "    print(\n",
    "        f\"Test accuracy: {round(avg_accuracy, 4)}, test loss: {round(avg_loss, 4)}, test MCC: {round(avg_MCC, 4)}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a5f41-b535-4ff1-b800-fc1b0a8428f7",
   "metadata": {},
   "source": [
    "### 1. Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456c86e9-ed51-48d3-9d00-71a4f77d7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bert = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    classifier_dropout=0.5,\n",
    ")\n",
    "\n",
    "model_bert.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad99037f-42a1-4e8d-b2e9-084027477fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_bert.parameters(),\n",
    "    lr=2e-5,\n",
    "    # eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6c3a340-680c-4d36-a9ff-d1bcceb255c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "total_steps = len(dataloader_train_bert) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b95bf91b-cfaa-4645-850b-77e8e6e75644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.7975, eval loss: 0.4581\n",
      "Eval accuracy: 0.8036, eval loss: 0.4622\n",
      "Eval accuracy: 0.8164, eval loss: 0.4811\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_bert, dataloader_train_bert, dataloader_val_bert, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8b2909cb-3202-44f6-bcde-ead0b1bc63e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label=\"Train\")\n",
    "plt.plot(losses_ev, label=\"Eval\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()\n",
    "plt.savefig(\"res_bert.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3136db78-b141-419b-a1a4-61722572f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.823, test loss: 0.4705, test MCC: 0.5637\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_id_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9996072-f64f-46e7-a1d7-b0117a5e4998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8138, test loss: 0.5653, test MCC: 0.5458\n"
     ]
    }
   ],
   "source": [
    "test_model(model_bert, dataloader_test_od_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c58312-bfb4-4edf-a27b-63084eb41c1f",
   "metadata": {},
   "source": [
    "Kaggle res:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5eefb242-d675-4599-8168-f1e7a36cfd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_40323/2135350988.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"cola_in_domain_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "df_test.insert(1, \"Empty\", 0)\n",
    "df_test[\"Id\"] = 0\n",
    "\n",
    "dataloader_test = preprocess(df_test, tokenizer_bert, split=False, bs=100, rand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b9f1aab-a19a-40c7-9c2c-20dd5e7e2594",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_l = []\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model_bert(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "        logits = out[1]\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        logits_l += pred_flat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "73446cbe-98c6-4973-a64f-dd1326eafbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"cola_in_domain_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "468fafbc-4fd7-417b-874e-388bc7256bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Sentence\"] = logits_l\n",
    "df_test = df_test.rename(columns={\"Sentence\": \"Label\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1f776eb-8de2-447f-8ed0-c7bc3e455a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "439bcf6f-c07b-4a0c-a251-9a6c40105e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb1c91-5cb4-4804-b730-1468abca051b",
   "metadata": {},
   "source": [
    "### 2. GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e110b794-6623-487d-ad45-4a8ad0d2f52d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpt2 = GPT2ForSequenceClassification.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "model_gpt2.config.pad_token_id = model_gpt2.config.eos_token_id\n",
    "model_gpt2.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1448595-4d97-49d0-92cb-0e35802138a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_gpt2.parameters(),\n",
    "    lr=10e-5,\n",
    "    # eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50ef180e-f2aa-4cf1-9594-bfb1bc6a4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "\n",
    "total_steps = len(dataloader_train_gpt2) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07316047-acea-4da8-a850-cbfe72c5c522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.72, eval loss: 0.5833\n",
      "Eval accuracy: 0.7444, eval loss: 0.5421\n",
      "Eval accuracy: 0.7772, eval loss: 0.497\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_gpt2, dataloader_train_gpt2, dataloader_val_gpt2, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7edd1ef4-905b-4e89-a8fe-667156b9faa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label=\"Train\")\n",
    "plt.plot(losses_ev, label=\"Eval\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "902cb88a-c6bd-4ae9-9e1f-13a330c18433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7796, test loss: 0.5333, test MCC: 0.4433\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_id_gpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "66e55e9b-b403-4f29-bf82-00e63388211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7117, test loss: 0.6186, test MCC: 0.3004\n"
     ]
    }
   ],
   "source": [
    "test_model(model_gpt2, dataloader_test_od_gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231cc5d2-9df1-4571-823f-bf476af4d7d9",
   "metadata": {},
   "source": [
    "### 3. Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3d099223-01ea-4d5a-b680-4fdb72a22928",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/electra-small-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (embeddings_project): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "              (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_electra = ElectraForSequenceClassification.from_pretrained(\n",
    "    \"google/electra-small-discriminator\",\n",
    "    num_labels=2,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    ")\n",
    "model_electra.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "12d746ec-53f6-445d-ad4b-c00a64659955",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(\n",
    "    model_electra.parameters(),\n",
    "    lr=5e-5,\n",
    "    # eps=1e-8,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dca85cb9-8893-407e-94bd-297567828384",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "\n",
    "total_steps = len(dataloader_train_electra) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,  # Default value in run_glue.py\n",
    "    num_training_steps=total_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3091cd6b-7bbd-4db0-98ef-8035c7df4b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.7772, eval loss: 0.4907\n",
      "Eval accuracy: 0.7986, eval loss: 0.476\n",
      "Eval accuracy: 0.8414, eval loss: 0.4249\n",
      "Eval accuracy: 0.8219, eval loss: 0.4662\n",
      "Eval accuracy: 0.8344, eval loss: 0.4692\n",
      "Eval accuracy: 0.8242, eval loss: 0.5189\n",
      "Eval accuracy: 0.8289, eval loss: 0.5439\n",
      "Eval accuracy: 0.8422, eval loss: 0.5138\n"
     ]
    }
   ],
   "source": [
    "losses_tr, losses_ev = train(\n",
    "    model_electra, dataloader_train_electra, dataloader_val_electra, epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5276010e-83b7-42b6-8d37-af3c87e35f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses_tr, label=\"Train\")\n",
    "plt.plot(losses_ev, label=\"Eval\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5d89863d-b909-461c-86b0-60b80d148fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8408, test loss: 0.4908, test MCC: 0.6029\n"
     ]
    }
   ],
   "source": [
    "test_model(model_electra, dataloader_test_id_electra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72ee2071-2845-4b7d-825c-4832261623db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8104, test loss: 0.652, test MCC: 0.5523\n"
     ]
    }
   ],
   "source": [
    "test_model(model_electra, dataloader_test_od_electra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "38d8e650-e49e-4af1-b449-55ae66bf14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_l = []\n",
    "\n",
    "for batch in dataloader_test:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model_electra(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels,\n",
    "        )\n",
    "        logits = out[1]\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "        logits_l += pred_flat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c598d60a-4d64-4aea-84e3-6c325be5f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"cola_in_domain_test.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "df_test[\"Sentence\"] = logits_l\n",
    "df_test = df_test.rename(columns={\"Sentence\": \"Label\"})\n",
    "df_test.to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
