{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8kHb7uHwOEN",
    "outputId": "7dfa7fd5-e6f6-47d4-bb63-adfd9a6eaf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[pytorch] in /opt/conda/lib/python3.8/site-packages (4.15.0)\n",
      "\u001b[33mWARNING: transformers 4.15.0 does not provide the extra 'pytorch'\u001b[0m\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (0.0.47)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[pytorch]) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers[pytorch]) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (2021.10.8)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers[pytorch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working example: https://mccormickml.com/2019/07/22/BERT-fine-tuning/#2-loading-cola-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5iZN97jT9mHJ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Sampler, TensorDataset, WeightedRandomSampler\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    GPT2Model,\n",
    "    GPT2TokenizerFast,\n",
    ")\n",
    "\n",
    "zipurl = \"https://nyu-mll.github.io/CoLA/cola_public_1.1.zip\"\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall(\"data\")\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://github.com/ncullen93/torchsample/blob/master/torchsample/samplers.py#L22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/nyu-mll/CoLA-baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting embeddings\n",
    "\n",
    "Taken from: https://github.com/BramVanroy/bert-for-inference/blob/master/introduction-to-bert.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_acceptability(nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BERT_acceptability, self).__init__()\n",
    "        self.model = BertModel.from_pretrained(\n",
    "            \"bert-base-uncased\", output_hidden_states=True\n",
    "        )\n",
    "        self.ln1 = nn.Linear(1, 33)\n",
    "        self.ln2 = nn.Linear(33, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, input_ids, attention):\n",
    "        out = self.model(input_ids=input_ids,\n",
    "                         attention_mask=attention)\n",
    "        hidden_state = out.last_hidden_state\n",
    "        out = torch.mean(hidden_state, dim=1).squeeze()\n",
    "        encoding = nn.functional.max_pool1d(out, out.shape[1])\n",
    "        encoding = self.dropout(encoding)\n",
    "        hidden = self.tanh(self.dropout(self.ln1(encoding)))\n",
    "        return self.sigmoid(self.ln2(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2226: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29263/2165484914.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/cola_public/raw/in_domain_train.tsv\",\n",
    "    sep=\"\\t\",\n",
    "    names=[\"Grammaticality\", \"Empty\", \"Sentence\"],\n",
    ")\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "texts = df.iloc[:, 2].to_list()[0:7000]\n",
    "labels = torch.from_numpy(df.iloc[:, 0].to_numpy()[0:7000])\n",
    "\n",
    "def get_ids(texts):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in texts:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = 64,           # Pad & truncate all sentences.\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   # Construct attn. masks.\n",
    "                            return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )    \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "input_ids, attention_masks = get_ids(texts)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "counts = np.bincount(labels.numpy())\n",
    "labels_weights = 1. / counts\n",
    "weights = labels_weights[labels.numpy()]\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "dataloader_train = DataLoader(dataset, batch_size=50, sampler=WeightedRandomSampler(weights, len(weights)))\n",
    "print('Original: ', texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overtfitting acc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 4923, 0: 2077})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7032857142857143"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(labels.numpy()))\n",
    "\n",
    "4923/7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "model = BERT_acceptability().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.BCELoss()\n",
    "# loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "# loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4258],\n",
       "        [0.3929],\n",
       "        [0.4134],\n",
       "        [0.3415],\n",
       "        [0.4853],\n",
       "        [0.4306],\n",
       "        [0.5088],\n",
       "        [0.4484],\n",
       "        [0.5571],\n",
       "        [0.3676],\n",
       "        [0.4433],\n",
       "        [0.2902],\n",
       "        [0.3129],\n",
       "        [0.4093],\n",
       "        [0.5302],\n",
       "        [0.4279],\n",
       "        [0.4105],\n",
       "        [0.4768],\n",
       "        [0.4016],\n",
       "        [0.5535]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids[0:20].to(device), attention_masks[0:20].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([_ for _ in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.4987142857142857, Mean loss = 0.7296926587820053, Correct = 3491/7000\n",
      "Accuracy = 0.5032857142857143, Mean loss = 0.7206330001354218, Correct = 3523/7000\n",
      "Accuracy = 0.5025714285714286, Mean loss = 0.7265349549906595, Correct = 3518/7000\n",
      "Accuracy = 0.49785714285714283, Mean loss = 0.7301270961761475, Correct = 3485/7000\n",
      "Accuracy = 0.49842857142857144, Mean loss = 0.7268531216042382, Correct = 3489/7000\n",
      "Accuracy = 0.5108571428571429, Mean loss = 0.7377713429076331, Correct = 3576/7000\n",
      "Accuracy = 0.5054285714285714, Mean loss = 0.7297754338809422, Correct = 3538/7000\n",
      "Accuracy = 0.49314285714285716, Mean loss = 0.7168134838342667, Correct = 3452/7000\n",
      "Accuracy = 0.5054285714285714, Mean loss = 0.7176029430968421, Correct = 3538/7000\n",
      "Accuracy = 0.5075714285714286, Mean loss = 0.7201052801949638, Correct = 3553/7000\n"
     ]
    }
   ],
   "source": [
    "glob_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    losses = []\n",
    "    for ids, attention, y in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(ids.to(device), attention.to(device))\n",
    "        correct += torch.sum(\n",
    "            torch.round(out).squeeze() == y.squeeze().to(device)\n",
    "        ).item()\n",
    "        loss = loss_fn(out.squeeze(), y.to(torch.float32).squeeze().to(device))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        losses.append(np.mean(loss.item()))\n",
    "    glob_loss.append(np.mean(losses))\n",
    "    accuracy = correct / len(dataset)\n",
    "    print(\n",
    "        f\"Accuracy = {accuracy}, Mean loss = {np.mean(losses)}, Correct = {correct}/7000\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 26, 0: 24})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5510],\n",
       "        [0.5253],\n",
       "        [0.5020],\n",
       "        [0.4496],\n",
       "        [0.5541],\n",
       "        [0.4084],\n",
       "        [0.2583],\n",
       "        [0.6073],\n",
       "        [0.3885],\n",
       "        [0.5184]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids[0:10].to(device), attention_masks[0:10].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f374f12a070>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(glob_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2239],\n",
       "        [0.6940],\n",
       "        [0.5437],\n",
       "        [0.6028],\n",
       "        [0.5003],\n",
       "        [0.3854],\n",
       "        [0.6037],\n",
       "        [0.5559],\n",
       "        [0.3122],\n",
       "        [0.4669],\n",
       "        [0.5585],\n",
       "        [0.4863],\n",
       "        [0.5556],\n",
       "        [0.6356],\n",
       "        [0.5411],\n",
       "        [0.4301],\n",
       "        [0.5550],\n",
       "        [0.6666],\n",
       "        [0.3831],\n",
       "        [0.5147]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids[100:120].to(device), attention_masks[100:120].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[100:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.iloc[:, 2].to_list()[7000:8000]\n",
    "ids, att = get_ids(texts)\n",
    "labels = torch.from_numpy(df.iloc[:, 0].to_numpy()[7000:8000])\n",
    "dataset = TensorDataset(ids, att, labels)  # create your datset\n",
    "dataloader_test = DataLoader(dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 723, 0: 277})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.723"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter(labels.numpy()))\n",
    "\n",
    "723/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7253999829292297\n",
      "0.4820000231266022\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "correct = 0\n",
    "for ids, att, y in dataloader_test:\n",
    "    out = model(ids.to(device), att.to(device))\n",
    "    correct += torch.sum(torch.round(out).squeeze() == y.squeeze().to(device))\n",
    "    # print(out.shape)x\n",
    "    loss = loss_fn(out.squeeze(), y.to(torch.float32).squeeze().to(device))\n",
    "    losses.append(np.mean(loss.item()))\n",
    "print(np.mean(losses))\n",
    "print((correct / 1000).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5295],\n",
       "        [0.5428],\n",
       "        [0.7278],\n",
       "        [0.6379],\n",
       "        [0.4998],\n",
       "        [0.4058],\n",
       "        [0.3623],\n",
       "        [0.4754],\n",
       "        [0.4822]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ids[1:10].to(device), att[1:10].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[1:10]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "recyling_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
