{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i8kHb7uHwOEN",
    "outputId": "7dfa7fd5-e6f6-47d4-bb63-adfd9a6eaf3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers[pytorch]\n",
      "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
      "     |████████████████████████████████| 3.4 MB 9.2 MB/s            \n",
      "\u001b[?25h\u001b[33mWARNING: transformers 4.15.0 does not provide the extra 'pytorch'\u001b[0m\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (2021.11.10)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (1.19.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "     |████████████████████████████████| 67 kB 354 kB/s             \n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers[pytorch]) (2.26.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "     |████████████████████████████████| 895 kB 86.5 MB/s            \n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     |████████████████████████████████| 3.3 MB 65.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[pytorch]) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers[pytorch]) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers[pytorch]) (2021.10.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from sacremoses->transformers[pytorch]) (1.1.0)\n",
      "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.4.0 sacremoses-0.0.47 tokenizers-0.10.3 transformers-4.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers[pytorch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5iZN97jT9mHJ"
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from transformers import GPT2TokenizerFast, GPT2Model, GPT2LMHeadModel\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "zipurl = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "with urlopen(zipurl) as zipresp:\n",
    "    with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "        zfile.extractall('data')\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XPinn6O5UgXw"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DKauTMVXNtjB"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pMa6SjTRD33W"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30700f4c6d04328baa2dc259057867d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74072664aaf435caea15a19c472f922",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34259d41c1e44fc5b0edfae1d9aa4739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f53e893bff47318c78c6c28cce4d56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# model = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o83la_uaTRpQ",
    "outputId": "2c156296-191e-4272-90ab-ee5df9abbbbc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca3f175883546f38903ad31c36d1624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would like to thank you mr chairman tensor(122.3064, grad_fn=<ExpBackward0>)\n",
      "i would liking to thanks you mr chair in tensor(1183.7665, grad_fn=<ExpBackward0>)\n",
      "thnks chair tensor(14135.1562, grad_fn=<ExpBackward0>)\n",
      "me not know english tensor(1978.1694, grad_fn=<ExpBackward0>)\n"
     ]
    }
   ],
   "source": [
    "gpt = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def score(tokens_tensor):\n",
    "    loss=gpt(tokens_tensor, labels=tokens_tensor)[0]\n",
    "    return torch.exp(loss)\n",
    "\n",
    "texts = ['i would like to thank you mr chairman', \n",
    "         'i would liking to thanks you mr chair in',\n",
    "         'thnks chair', 'me not know english']\n",
    "for text in texts:\n",
    "    tokens_tensor = tokenizer.encode( text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    # print(tokens_tensor)           \n",
    "    print(text, score(tokens_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYzkarQLGBBY",
    "outputId": "0948c5b3-9d65-409a-9a9e-68bb2862c66a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 1842, 345], [1639, 1842, 502]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['I love you', 'You love me']).get('input_ids')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXmPgHmEAFu_"
   },
   "source": [
    "Inspiration: https://github.com/nyu-mll/CoLA-baselines\n",
    "\n",
    "Build a module: https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb\n",
    "\n",
    "Counting suprisal: https://www.researchgate.net/publication/343268482_Investigating_the_Role_of_Verb_Frequency_in_Factive_and_Manner-of-speaking_Islands\n",
    "\n",
    "https://osf.io/98p2q/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "8Uhy3V2NFu9l"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class GPT2_acceptability(nn.Module):\n",
    "   def __init__(self):\n",
    "       super(GPT2_acceptability, self).__init__()\n",
    "       self.model = GPT2Model.from_pretrained('gpt2')\n",
    "       self.ln1 = nn.Linear(self.model.config.hidden_size, 384)\n",
    "       self.ln2 = nn.Linear(384, 192)\n",
    "       self.ln3 = nn.Linear(192, 30)\n",
    "       self.ln4 = nn.Linear(30, 1)\n",
    "\n",
    "   def forward(self, input_ids, attention_mask):\n",
    "       with torch.no_grad():\n",
    "        out = self.model(input_ids=input_ids,\n",
    "                         attention_mask=attention_mask)\n",
    "       out = out[0][:, 0, :]\n",
    "      #  print(out)\n",
    "       out = F.relu(self.ln1(out))\n",
    "       out = F.relu(self.ln2(out))\n",
    "       out = F.relu(self.ln3(out))\n",
    "       return F.sigmoid(self.ln4(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "lnz9bO9sUqzB"
   },
   "outputs": [],
   "source": [
    "# class GPT2_acceptability(nn.Module):\n",
    "#    def __init__(self):\n",
    "#        super(GPT2_acceptability, self).__init__()\n",
    "#        self.model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "#        self.ln1 = nn.Linear(1, 20)\n",
    "#        self.ln2 = nn.Linear(20, 50)\n",
    "#        self.ln3 = nn.Linear(50, 20)\n",
    "#        self.ln4 = nn.Linear(20, 1)\n",
    "\n",
    "#    def forward(self, input_ids, attention_mask):\n",
    "#        with torch.no_grad():\n",
    "#         #  out=self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "#         out=self.model(input_ids=input_ids, \n",
    "#                        labels=input_ids,\n",
    "#                        attention_mask=attention_mask)\n",
    "#       #  print(out.logits.shape)\n",
    "#        logits = out.logits \n",
    "#        print(logits.shape)\n",
    "#        loss = torch.softmax(logits, dim=-1).prod(2)\n",
    "       \n",
    "#        out = torch.exp(loss.unsqueeze(0))\n",
    "#        print(out)\n",
    "#       #  out = torch.sum(out.hidden_states \n",
    "#       #                  * torch.log2(F.softmax(out.logits)), axis=1)\n",
    "#        print(out.shape)\n",
    "#        out = F.relu(self.ln1(out))\n",
    "#        out = F.relu(self.ln2(out))\n",
    "#        out = F.relu(self.ln3(out))\n",
    "#        print(out.shape)\n",
    "#        return F.sigmoid(self.ln4(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "id": "JsD0psZR-dgZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M0lhFGUS_EeW",
    "outputId": "f2a12254-2791-4492-ff3e-e2a89bb69f6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "data/cola_public/raw/in_domain_train.tsv\n"
     ]
    }
   ],
   "source": [
    "!ls data/cola_public/raw/in_domain_train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "EAB2mBwfMLHZ",
    "outputId": "392d988f-175f-4e31-eae3-eb93145f49be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grammaticality</th>\n",
       "      <th>Empty</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gj04</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our friends won't buy this analysis, let alone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gj04</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization and I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gj04</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>One more pseudo generalization or I'm giving up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gj04</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The more we study verbs, the crazier they get.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gj04</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Day by day the facts are getting murkier.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Poseidon appears to own a dragon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Digitize is my happiest memory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It is easy to slay the Gorgon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I had the strangest feeling that I knew you.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ad03</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What all did you get for Christmas?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8551 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Grammaticality Empty                                           Sentence\n",
       "gj04               1   NaN  Our friends won't buy this analysis, let alone...\n",
       "gj04               1   NaN  One more pseudo generalization and I'm giving up.\n",
       "gj04               1   NaN   One more pseudo generalization or I'm giving up.\n",
       "gj04               1   NaN     The more we study verbs, the crazier they get.\n",
       "gj04               1   NaN          Day by day the facts are getting murkier.\n",
       "...              ...   ...                                                ...\n",
       "ad03               0     *                   Poseidon appears to own a dragon\n",
       "ad03               0     *                     Digitize is my happiest memory\n",
       "ad03               1   NaN                     It is easy to slay the Gorgon.\n",
       "ad03               1   NaN       I had the strangest feeling that I knew you.\n",
       "ad03               1   NaN                What all did you get for Christmas?\n",
       "\n",
       "[8551 rows x 3 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cola_public/raw/in_domain_train.tsv', sep='\\t', names=['Grammaticality', 'Empty', 'Sentence'])\n",
    "df\n",
    "# df = pd.read_csv('in_domain_train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "id": "bSyu6oWPKvCQ"
   },
   "outputs": [],
   "source": [
    "def encode(data, tokenizer):\n",
    "    input_ids = []    \n",
    "    attention_mask = []    \n",
    "    for text in data:        \n",
    "      tokenized_text = tokenizer.encode_plus(text,\n",
    "                                            max_length=100,\n",
    "                                            # add_special_tokens =True,\n",
    "                                            pad_to_max_length=True,\n",
    "                                            return_attention_mask=True)        \n",
    "      input_ids.append(tokenized_text['input_ids'])        \n",
    "      attention_mask.append(tokenized_text['attention_mask'])\n",
    "    # print(tokenized_text)\n",
    "    \n",
    "    return torch.tensor(input_ids, dtype=torch.long), torch.tensor(attention_mask, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "id": "IeDmgQzsxmP1"
   },
   "outputs": [],
   "source": [
    "texts = df.iloc[:,2].to_list()[0:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jHHVyUASKyeh",
    "outputId": "bf535ebb-3b15-407b-e2d3-7bf5f643c95c"
   },
   "outputs": [],
   "source": [
    "ids, attention = encode(texts, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sawcsEAzQVg4",
    "outputId": "46cbc217-0b3a-4735-ae34-89c40b2929f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kVWVooDHQbEN",
    "outputId": "2eab96be-2958-4d72-a563-1de4ed4f0fdc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 100])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JA5Z9aAQKsO",
    "outputId": "44a24a9c-8781-4039-a04c-e0f24f325095"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6000, 100])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "id": "mHjbERv6LvhZ"
   },
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(df.iloc[:,0].to_numpy()[0:6000])\n",
    "dataset = TensorDataset(ids, attention, labels) # create your datset\n",
    "dataloader_train = DataLoader(dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "AkfUnBgdQ5oh"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_epochs = 20\n",
    "\n",
    "model = GPT2_acceptability().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aIFnPW3Z4Kjh",
    "outputId": "97bdcb33-86b8-49a2-963f-21feb55e26be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3198,   517, 24543,  2276,  1634,   290,   314,  1101,  3501,   510,\n",
       "           13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "id": "R6ujPj_1sd00",
    "outputId": "2fba94c7-3f37-441b-d777-562a12c26861"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4959],\n",
       "        [0.4959],\n",
       "        [0.4952],\n",
       "        [0.4988],\n",
       "        [0.5055],\n",
       "        [0.4934],\n",
       "        [0.4943],\n",
       "        [0.5009],\n",
       "        [0.5054],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.5009],\n",
       "        [0.5009],\n",
       "        [0.5009],\n",
       "        [0.4933],\n",
       "        [0.4933],\n",
       "        [0.4933],\n",
       "        [0.4943],\n",
       "        [0.5009],\n",
       "        [0.4934],\n",
       "        [0.4938],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4927],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4968],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4927],\n",
       "        [0.4927],\n",
       "        [0.4927],\n",
       "        [0.4927],\n",
       "        [0.4927],\n",
       "        [0.4927],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4949],\n",
       "        [0.4949],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4943],\n",
       "        [0.4952],\n",
       "        [0.4924],\n",
       "        [0.5031],\n",
       "        [0.4919],\n",
       "        [0.4952],\n",
       "        [0.5031],\n",
       "        [0.4938],\n",
       "        [0.4938],\n",
       "        [0.4915],\n",
       "        [0.5031],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4952],\n",
       "        [0.4943],\n",
       "        [0.5016],\n",
       "        [0.4952],\n",
       "        [0.4952]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(ids[1:100].to(device), attention[1:100].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "HgZddWqwPz4F",
    "outputId": "2d8a4de2-3fb3-476e-f44b-5dcdb48dde8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6357235431671142\n",
      "Accuracy = 0.68\n",
      "0.6201017359892528\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6196066836516062\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6194096008936564\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6196467200915019\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6190704007943472\n",
      "Accuracy = 0.6903333333333334\n",
      "0.619253675142924\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6187887748082479\n",
      "Accuracy = 0.6903333333333334\n",
      "0.618436727921168\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6183704018592835\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6182117819786072\n",
      "Accuracy = 0.6903333333333334\n",
      "0.617965829372406\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6180114308993022\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6181561827659607\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6178217172622681\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6175705075263977\n",
      "Accuracy = 0.6903333333333334\n",
      "0.617513773838679\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6178864558537801\n",
      "Accuracy = 0.6903333333333334\n",
      "0.617133084932963\n",
      "Accuracy = 0.6903333333333334\n",
      "0.6172210852305094\n",
      "Accuracy = 0.6903333333333334\n"
     ]
    }
   ],
   "source": [
    "glob_loss = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  correct = 0\n",
    "  losses = []\n",
    "  for ids, attention, y in dataloader_train:\n",
    "    out = model(ids.to(device), attention.to(device))\n",
    "    correct += torch.sum(torch.round(out).squeeze() == y.squeeze().to(device)).item()\n",
    "    loss = loss_fn(out.squeeze(), y.to(torch.float32).squeeze().to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    losses.append(np.mean(loss.item()))\n",
    "    optimizer.step()\n",
    "    # scheduler.step()\n",
    "  print(np.mean(losses))\n",
    "  glob_loss.append(np.mean(losses))\n",
    "  accuracy = correct / len(dataset)\n",
    "  print(\"Accuracy = {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "id": "j6ii9i-WwwqL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f46634ca1f0>]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(glob_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "AGwGk8XS1AH1"
   },
   "outputs": [],
   "source": [
    "texts_test = df.iloc[:,2].to_list()[6000:8000]\n",
    "ids, attention = encode(texts_test, tokenizer)\n",
    "labels = torch.from_numpy(df.iloc[:,0].to_numpy()[6000:8000])\n",
    "dataset = TensorDataset(ids, attention, labels) # create your datset\n",
    "dataloader_train = DataLoader(dataset, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "correct = 0\n",
    "for ids, attention, y in dataloader_train:\n",
    "    out = model(ids.to(device), attention.to(device))\n",
    "    correct += torch.sum(torch.round(out).squeeze() == y.squeeze().to(device))\n",
    "    # print(out.shape)x\n",
    "    loss = loss_fn(out.squeeze(), y.to(torch.float32).squeeze().to(device))\n",
    "    losses.append(np.mean(loss.item()))\n",
    "print(np.mean(losses))\n",
    "print((correct / len(dataset)).item())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "recyling_transformers.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
